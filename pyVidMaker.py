import os, hashlib, subprocess, logging, pprint, datetime, glob, shutil, requests
from bs4 import BeautifulSoup
import urllib.parse
import xml.etree.ElementTree as ET
from optparse import OptionParser
from gtts import gTTS
from imageSelect import imageSelect
from urllib.parse import quote_plus

# Set up logging
#logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

def setup_logging(log_file):
    """
    Configures logging settings to record events, errors, and status messages.
    """
    logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s', filename=log_file)

def execute_command(command):
    """
    Executes a command in the system and logs the command line and output.
    """
    try:
        logging.info(f"Executing command: {command}")
        result = subprocess.run(command, shell=True, capture_output=True, text=True)
        logging.info(f"Command output: {result.stdout.strip()}")
        if result.stderr:
            logging.error(f"Command error: {result.stderr.strip()}")
    except Exception as e:
        logging.error(f"Error executing command: {e}")

def search_images(search_query, num_images, output_directory):
    search_images_pexels(search_query, num_images, output_directory)
    search_images_pixabay(search_query, num_images, output_directory)
    #search_images_google(search_query, num_images, output_directory)
    #search_images_bing(search_query, num_images, output_directory)

pexels_API_KEY = "YOUR_API_KEY"
pexels_API_KEY = "JMdcZ8E4lrykP2QSaZHNxuXKlJRRjmmlvBQRvgu5CrHnSI30BF7mGLI7"

def search_images_pexels(query, num_images, output_directory):
    base_url = "https://api.pexels.com/v1/search"
    headers = {"Authorization": pexels_API_KEY}
    params = {"query": query, "per_page": num_images}

    response = requests.get(base_url, headers=headers, params=params)

    if response.status_code == 200:
        data = response.json()
        photos = data.get("photos", [])

        if not photos:
            print("No images found.")
            return

        # Create output directory if it doesn't exist
        os.makedirs(output_directory, exist_ok=True)

        # Download and save images
        for photo in photos:
            image_url = photo["src"]["original"]
            image_id = photo["id"]
            image_extension = image_url.split(".")[-1]
            image_filename = f"pexels_{image_id}.{image_extension}"
            image_path = os.path.join(output_directory, image_filename)

            response = requests.get(image_url)
            if response.status_code == 200:
                with open(image_path, "wb") as file:
                    file.write(response.content)
                print(f"Downloaded image: {image_filename}")
            else:
                print(f"Error downloading image {image_filename}. Status code: {response.status_code}")

        print(f"{num_images} images downloaded to {output_directory}")
    else:
        print(f"Error occurred while searching images. Status code: {response.status_code}")

pixabay_API_KEY = "YOUR_API_KEY"
pixabay_API_KEY = "abcdefghijklmnopqrstuvwxyz"

def search_images_pixabay(query, num_images, output_directory):
    base_url = "https://pixabay.com/api/"
    params = {
        "key": pixabay_API_KEY,
        "q": query,
        "per_page": num_images
    }
    response = requests.get(base_url, params=params)
    if response.status_code == 200:
        data = response.json()
        images = data.get("hits", [])
        if not images:
            print("No images found.")
            return
        # Create output directory if it doesn't exist
        os.makedirs(output_directory, exist_ok=True)
        # Download and save images
        for i, image in enumerate(images):
            image_url = image["largeImageURL"]
            image_id = image["id"]
            image_extension = image_url.split(".")[-1]
            image_filename = f"pixabay_{image_id}.{image_extension}"
            image_path = os.path.join(output_directory, image_filename)
            response = requests.get(image_url)
            if response.status_code == 200:
                with open(image_path, "wb") as file:
                    file.write(response.content)
                print(f"Downloaded image {i+1}/{num_images}: {image_filename}")
            else:
                print(f"Error downloading image {i+1}/{num_images}. Status code: {response.status_code}")
        print(f"{num_images} images downloaded to {output_directory}")
    else:
        print(f"Error occurred while searching images. Status code: {response.status_code}")

def search_images_bing(search_query, num_images, output_directory):
    # Prepare search query URL
    search_query_encoded = quote_plus(search_query)
    url = f"https://www.bing.com/images/search?q={search_query_encoded}"

    # Send a GET request to Bing Images
    response = requests.get(url)

    # Create BeautifulSoup object
    soup = BeautifulSoup(response.content, 'html.parser')

    # Find all image elements
    image_elements = soup.find_all('img')

    # Create output directory if it doesn't exist
    os.makedirs(output_directory, exist_ok=True)

    # Download and save images
    count = 0
    for image in image_elements:
        if count >= num_images:
            break

        if 'src' in image.attrs:
            image_url = image['src']
            try:
                response = requests.get(image_url)
                image_path = os.path.join(output_directory, f"bing_image{count}.jpg")
                with open(image_path, 'wb') as file:
                    file.write(response.content)
                count += 1
            except Exception as e:
                print(f"Error downloading image: {e}")

    print(f"Downloaded {count} images to {output_directory}")

def search_images_google(search_query, num_images, output_directory):
    # Prepare search query URL
    search_query_encoded = quote_plus(search_query)
    url = f"https://www.google.com/search?q={search_query_encoded}&tbm=isch"
    # Send a GET request to Google Images
    response = requests.get(url)
    # Create BeautifulSoup object
    soup = BeautifulSoup(response.content, 'html.parser')
    # Find all image elements
    image_elements = soup.find_all('img')
    # Create output directory if it doesn't exist
    os.makedirs(output_directory, exist_ok=True)
    # Download and save full-resolution images
    count = 0
    for image in image_elements:
        if count >= num_images:
            break
        if 'src' in image.attrs:
            image_url = image['src']
        elif 'data-src' in image.attrs:
            image_url = image['data-src']
        else:
            continue
        try:
            response = requests.get(image_url)
            image_path = os.path.join(output_directory, f"google_image{count}.jpg")
            with open(image_path, 'wb') as file:
                file.write(response.content)
            count += 1
        except Exception as e:
            print(f"Error downloading image: {e}")
    print(f"Downloaded {count} images to {output_directory}")

def generate_tts_audio_buffer(audio_buffer_file, text_content):
    """
    Generates a TTS audio buffer using GTTS from the provided text content
    and saves it to the specified audio buffer file.
    """
    if not file_exists(audio_buffer_file):
        tts = gTTS(text=text_content)
        tts.save(audio_buffer_file)

def file_exists(file_path):
    """
    Checks if a file exists at the given file path.
    Returns True if it exists, False otherwise.
    """
    if file_path is not None:
        return os.path.isfile(file_path)
    return None

def get_missing_file(type, file_path, description, script):
    if file_path:
        log=logging.info
        verb="Acquiring"
        log(f"{verb} {type}: {file_path}\n\tDescription: {description}\n\tScript: {script}")
        if type=="TTS": 
            verb="Generated"
            generate_tts_audio_buffer(file_path, script)
        elif type=="Image":
            verb="Found"
            search_images(description, 20, 'image_temp')
            print(';getting image')
            imgs=imageSelect()
            imgs.interface(file_path, glob.glob('image_temp/*'), description)
            shutil.rmtree('image_temp')
        missing=0 if file_exists(file_path) else 1
        if missing>0:
            verb="Missing"
            log=logging.warning
        log(f"{verb} {type}: {file_path}")
        return missing
    return 0

def generate_temp_filename(fnkey=None):
    # Add your code to generate a unique temporary filename here
    # Example implementation: Use a timestamp-based filename
    if(fnkey):
        return "temp_"+hashlib.md5(fnkey).hexdigest()
    
    timestamp = datetime.datetime.now().strftime("%Y%m%d%H%M%S")
    return f"temp_{timestamp}"

def parse_video_script(filename):
    tree = ET.parse(filename)
    root = tree.getroot()
    
    clips = []
    
    # Retrieve global defaults
    global_defaults = root.find("Defaults")
    global_defaults_dict = {}
    parent_map = {c: p for p in root.iter() for c in p}
    if global_defaults is not None:
        for child in global_defaults:
            global_defaults_dict[child.tag] = child.text
    
    # Retrieve all clips in the script
    all_clips = root.findall(".//Clip")
    for clip_element in all_clips:
        clip_dict = global_defaults_dict.copy()
        # Check if the clip is within a chapter
        parent = parent_map[clip_element]
        if parent.tag == "Chapter":
            chapter_defaults = parent.find("Defaults")
            if chapter_defaults is not None:
                for child in chapter_defaults:
                    clip_dict[child.tag] = child.text
        
        # Override defaults with clip-specific settings
        clip_defaults = clip_element.find("Properties")
        if clip_defaults is not None:
            for child in clip_defaults:
                clip_dict[child.tag] = child.text 
       
        # Add clip filename metadata
        clip_dict["ClipFileName"] = generate_temp_filename() + ".mp4"
        media_elements = clip_element.findall(".//Media")
        media_list = []
        for media_element in media_elements:
            media_dict = {"MediaType": media_element.get("type")}
            for child in media_element:
                media_dict[child.tag] = child.text
            if media_dict.get("MediaType") == "TTS":
                if media_dict.get('FilePath')=="":
                    media_dict['FilePath']=generate_temp_filename()+".wav"
            media_list.append(media_dict)

        clip_dict["Media"] = media_list
        clips.append(clip_dict)
    return clips

def check_missing_media(clips):
    """ also check for background audio file from global, chapter, clip """
    missing=0
    for clip in clips:
        media_list = clip.get("Media", [])
        for media in media_list:
            media_type = media.get("MediaType")
            file_path = media.get("FilePath")
            buffer_file = media.get("BufferFile")
            script = media.get('Script')
            description = media.get("Description")
            if media_type:
                # Process missing media
                if not file_exists(file_path):
                    missing+=get_missing_file(media_type, file_path, description, script)
                if not file_exists(buffer_file):
                    missing+=get_missing_file(media_type, buffer_file, description, script)
    return missing

def convert_file_format(input_file, output_file, output_format):
    """
    Converts a media file from one format to another using FFmpeg.
    """
    command = f"ffmpeg -i {input_file} -y {output_file}"
    execute_command(command)

def adjust_volume(input_file, output_file, volume_level):
    """
    Adjusts the volume level of an audio file using FFmpeg.
    """
    command = f"ffmpeg -i {input_file} -af 'volume={volume_level}' -y {output_file}"
    execute_command(command)

def get_longest_media_duration(media_list):
    """
    Returns the duration of the longest piece of media with audio
    (video, audio, or TTS) from a list of media elements.
    """
    longest_duration = 0
    for media in media_list:
        if 'Duration' in media:
            duration = media['Duration']
            if duration > longest_duration:
                longest_duration = duration
        else:
            """Also get natural durations"""
            """set 'duration' to the natural duration"""
            pass
    return longest_duration

def generate_clip(xml_clip_data):
    """
    Generates a video clip based on the provided XML clip data,
    handling the positioning and timing of media elements within the clip.
    """
    # Implement clip generation logic based on XML data

def concatenate_clips(clips_list, background_audio_file, output_file):
    """
    Concatenates the video clips from a list into a final video,
    overlays the background audio, and saves it to the output file.
    """
    # Implement clip concatenation and background audio merging logic using FFmpeg

def create_subtitle_track(clips_list, output_file):
    """
    Creates a subtitle track for the video based on the durations of the clips
    and saves it to the output file.
    """
    # Implement subtitle track creation logic
def main():
    parser=OptionParser(usage="usage: %prog [options] xmlVideoScript.xml")
    parser.add_option("-c", "--check", dest="check", default=False,
            help="Don't render, only check the XML and find missing media.")
 
    (options, args)=parser.parse_args()
    if len(args)==0:
        parser.print_help()
        return
    # Input XML file
    xml_file = args[0]
    basefn,ext= os.path.splitext(xml_file)
    # Output video file
    output_file =basefn+".mp4"
    # Log file
    log_file = basefn+".log"
    # Set up logging
    setup_logging(log_file)

    #try:
    if True:
        clips = parse_video_script(xml_file)
        for clip in clips:
            pprint.pprint(clip)

        missing=check_missing_media(clips)
        if(missing):
            logging.error(f'There are {missing} missing media files.')
        else:
            pass
        # Parse the XML file
        #xml_data = parse_xml_file(xml_file)
        #print(ET.tostring(xml_data, encoding="unicode"))
        # Generate TTS audio buffers
#        for clip in xml_data['clips']:
#            for media in clip['media']:
#                if media['type'] == 'TTS':
#                    generate_tts_audio_buffer(media['content'], media['AudioBufferFile'])

        # Generate video clips
#        clips_list = []
#        for clip in xml_data['clips']:
#            generated_clip = generate_clip(clip)
#            clips_list.append(generated_clip)

        # Concatenate clips and merge background audio
#        concatenate_clips(clips_list, xml_data['BackgroundMusic'], output_file)

        # Create subtitle track
#        create_subtitle_track(clips_list, output_file)

            logging.info("Video generation completed successfully.")
#    except Exception as e:
#        logging.error(f"Error during video generation: {e}")

if __name__ == "__main__":
    main()



